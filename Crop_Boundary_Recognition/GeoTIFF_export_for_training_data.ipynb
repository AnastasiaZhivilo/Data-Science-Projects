{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Z2-IRwe44XCsESHcYnKi2_gbo0xJt7U6",
      "authorship_tag": "ABX9TyMx8OeLyb+7yecGswnroyzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiaZhivilo/Data-Science-Projects/blob/main/Crop_Boundary_Recognition/GeoTIFF_export_for_training_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise Google Drive and the Google Project cs88-2-capstone"
      ],
      "metadata": {
        "id": "PUxH7XdnxW67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please enable GPU runtime in Colab"
      ],
      "metadata": {
        "id": "iFquVxOV58Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install rasterio"
      ],
      "metadata": {
        "id": "h3mZfnngPkAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import ee\n",
        "import geemap\n",
        "import ee.batch\n",
        "import os\n",
        "from google.colab import drive\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Import the necessary component directly from ipyleaflet\n",
        "try:\n",
        "    from ipyleaflet import DrawControl\n",
        "except ImportError:\n",
        "    print(\"ipyleaflet DrawControl could not be imported. Please ensure geemap is installed.\")\n",
        "    # Stop execution if the critical component is missing\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "cCdwH1IbIEny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate the Google Project and connect to Google Drive"
      ],
      "metadata": {
        "id": "r0Eq0rusaGqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "# 2. Authenticate and initialise Google Earth Engine\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='cs88-2-capstone')\n",
        "print(\"Earth Engine authenticated and initialized.\")"
      ],
      "metadata": {
        "id": "dSpDQEmcQFfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a central geographical point and define a boundary box"
      ],
      "metadata": {
        "id": "JUp-2hdvhfVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Define the central point\n",
        "center_lon = 146.9561\n",
        "center_lat = -34.7022\n",
        "center_point = ee.Geometry.Point(center_lon, center_lat)\n",
        "\n",
        "# 2. Define the size (radius) for the buffer in meters\n",
        "buffer_radius_meters = 5000  # 15 kilometers\n",
        "\n",
        "# 3. Create a geodesic buffer (circle) around the point\n",
        "circle_geometry = center_point.buffer(buffer_radius_meters)\n",
        "\n",
        "# 4. Get the Bounding Box (Rectangle) coordinates from the buffered geometry\n",
        "# .bounds() returns an ee.Geometry.Rectangle\n",
        "bounding_box_geom = circle_geometry.bounds()\n",
        "\n",
        "bbox_coords = bounding_box_geom.getInfo()['coordinates'][0]\n",
        "\n",
        "# 5. Set up a folder name for this bounding box\n",
        "folder_name = f\"BBox_{center_lon:.4f}_{center_lat:.4f}\".replace('.', '_').replace('-', '_')"
      ],
      "metadata": {
        "id": "Git2UJnKhegl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Sentinel-2 data for visualisation purposes, to allow for manual data labeling"
      ],
      "metadata": {
        "id": "bBVURTx0aPl1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6vAxqUaoLTI"
      },
      "source": [
        "\n",
        "# Set up Cloud masking function:\n",
        "def mask_s2_clouds(image):\n",
        "  \"\"\"Masks clouds in a Sentinel-2 image using the QA band.\n",
        "\n",
        "  Args:\n",
        "      image (ee.Image): A Sentinel-2 image.\n",
        "\n",
        "  Returns:\n",
        "      ee.Image: A cloud-masked Sentinel-2 image.\n",
        "  \"\"\"\n",
        "  qa = image.select('QA60')\n",
        "\n",
        "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloud_bit_mask = 1 << 10\n",
        "  cirrus_bit_mask = 1 << 11\n",
        "\n",
        "  # Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = (\n",
        "      qa.bitwiseAnd(cloud_bit_mask).eq(0)\n",
        "      .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
        "  )\n",
        "\n",
        "  return image.updateMask(mask).divide(10000)\n",
        "\n",
        "\n",
        "# Define date range\n",
        "start_date = '2023-09-01'\n",
        "end_date = '2024-09-15'\n",
        "\n",
        "\n",
        "# Extract Sentinel-2 data for RGB bands with cloud masking\n",
        "image = (\n",
        "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "    .filterDate(start_date, end_date)\n",
        "    # Pre-filter to get less cloudy granules.\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "    .map(mask_s2_clouds)\n",
        ")\n",
        "\n",
        "visualization = {\n",
        "    'min': 0.0,\n",
        "    'max': 0.3,\n",
        "    'bands': ['B4','B3','B2'],\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define date range\n",
        "start_date = '2024-07-01'\n",
        "end_date = '2024-09-15'\n"
      ],
      "metadata": {
        "id": "C0K1GgcMg5AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up an interactive map in the boundary box that will allow to extract geographic information of the polygons"
      ],
      "metadata": {
        "id": "WvBRSffTbXuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this draw all the necessary polygons on the map, the coordinates will be displayed below the map, these coordinates will be used later to create GeoTIFF files"
      ],
      "metadata": {
        "id": "PlJLl0BobkV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a median composite of the filtered image collection\n",
        "median_image = image.median().clip(bounding_box_geom)\n",
        "print(\"Median image composite created and clipped to bounding box.\")\n",
        "\n",
        "# 1. Initialize the geemap interactive map\n",
        "Map = geemap.Map(center=[center_lat, center_lon], zoom=12)\n",
        "\n",
        "# 2. Add the clipped median image to the map\n",
        "Map.add_ee_layer(median_image, visualization, 'Median Sentinel-2 Image')\n",
        "\n",
        "# 3. Fit the map view to the bounding box\n",
        "Map.zoom_to_bounds(bounding_box_geom.bounds().getInfo().get('coordinates')[0])\n",
        "print(\"Map view adjusted to bounding box.\")\n",
        "\n",
        "# 4. Manually create the DrawControl object with TraitError-compliant arguments ðŸ› ï¸\n",
        "# The fix: Pass an empty dictionary {} to disable tools while satisfying the TraitError.\n",
        "if DrawControl is not None:\n",
        "    # ðŸŒŸ Configuration for the ONLY tool we want enabled: Polygon\n",
        "    polygon_config = {\n",
        "        'shapeOptions': {\n",
        "            'fillColor': '#ff0000',\n",
        "            'color': '#ff0000',\n",
        "            'fillOpacity': 0.1,\n",
        "            'weight': 2\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create the DrawControl, using {} to effectively disable tools\n",
        "    draw_control = DrawControl(\n",
        "        # The tool we want enabled\n",
        "        polygon=polygon_config,\n",
        "\n",
        "        # Tools we must disable by passing an EMPTY DICT {}\n",
        "        polyline={}, # Disables polyline\n",
        "        rectangle={}, # Disables rectangle\n",
        "        circle={}, # Disables circle\n",
        "        marker={}, # Disables marker\n",
        "\n",
        "        # Control options\n",
        "        edit=False,\n",
        "        remove=False,\n",
        "        position='topleft'\n",
        "    )\n",
        "\n",
        "    # Add the manually created control to the geemap object\n",
        "    Map.add_control(draw_control)\n",
        "    print(\"Drawing tools added to the map (Polygon only).\")\n",
        "\n",
        "    # 5. Define a function to execute when a drawing is completed\n",
        "    def handle_draw(target, action, geo_json):\n",
        "        \"\"\"\n",
        "        Callback function that runs when a user finishes drawing a feature.\n",
        "        \"\"\"\n",
        "        # The geo_json argument contains the GeoJSON of the drawn feature\n",
        "        if geo_json:\n",
        "            geometry = geo_json.get('geometry')\n",
        "            coordinates = geometry.get('coordinates')\n",
        "            geometry_type = geometry.get('type')\n",
        "\n",
        "            print(f\"\\n--- Drawn {geometry_type} Coordinates ---\")\n",
        "            if geometry_type == 'Polygon':\n",
        "                # For a Polygon, the exterior ring coordinates are the first element of the list\n",
        "                print(f\"Exterior Ring Coordinates (GeoJSON format): {coordinates[0]}\")\n",
        "            else:\n",
        "                print(f\"Coordinates (GeoJSON format): {coordinates}\")\n",
        "            print(\"----------------------------------------\")\n",
        "\n",
        "            # Since the drawn feature is stored in geo_json, we don't need to manually clear a buffer.\n",
        "\n",
        "    # 6. Attach the callback function to the control's 'on_draw' event\n",
        "    draw_control.on_draw(handle_draw)\n",
        "\n",
        "# 7. Display the map\n",
        "print(\"Displaying interactive map. Use the Polygon tool (top-left) to draw polygons.\")\n",
        "Map"
      ],
      "metadata": {
        "id": "DJ286hup5H2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function that will convert polygon coordinates into a GeoTIFF file"
      ],
      "metadata": {
        "id": "I1nmFTXKcMCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "resolution_meters = 10                   # Spatial resolution of the GeoTIFF (e.g., 10m for Sentinel-2 data)\n",
        "\n",
        "# --- GEOFFI EXPORT LOGIC (UPDATED FOR INSTANCE SEGMENTATION) ---\n",
        "\n",
        "def export_polygon_to_geotiff(coords, name, folder, scale):\n",
        "    \"\"\"\n",
        "    UPDATED: Exports the ENTIRE FILLED POLYGON AREA (not just the boundary line)\n",
        "    as a GeoTIFF. This is essential for generating the instance segmentation\n",
        "    Distance Map in the training script.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Create the Earth Engine Polygon Geometry\n",
        "        ee_polygon = ee.Geometry.Polygon(coords)\n",
        "        print(f\"\\n--- Starting Export for {name} ---\")\n",
        "\n",
        "        # CONVERT GEOMETRY TO FEATURE COLLECTION:\n",
        "        ee_feature_collection = ee.FeatureCollection([ee.Feature(ee_polygon)])\n",
        "\n",
        "        # 2. Rasterize the Geometry (Paint it onto an Image)\n",
        "        empty_image = ee.Image.constant(0).rename('field_interior')\n",
        "\n",
        "        # Paint the feature collection onto the image, assigning a value (e.g., 1)\n",
        "        # The 'width' parameter is removed, causing the polygon to be FILLED.\n",
        "        rasterized_image = empty_image.paint(\n",
        "            featureCollection=ee_feature_collection,\n",
        "            color=1\n",
        "            # width=1 is removed here\n",
        "        ).reproject(crs='EPSG:4326', scale=scale)\n",
        "\n",
        "        print(\"Filled geometry rasterized successfully.\")\n",
        "\n",
        "        # 3. Define Export Parameters and Start Task\n",
        "        # Note: The output is now the 'filled' area for a single field instance.\n",
        "        export_task = ee.batch.Export.image.toDrive(\n",
        "            image=rasterized_image,\n",
        "            description=name,\n",
        "            folder=folder,\n",
        "            fileNamePrefix=name,\n",
        "            region=ee_polygon.bounds(),\n",
        "            scale=scale,\n",
        "            fileFormat='GeoTIFF'\n",
        "        )\n",
        "\n",
        "        export_task.start()\n",
        "\n",
        "        print(f\"Task Name: {name} STARTED (Exporting Filled Area).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred during export of {name}: {e}\")\n"
      ],
      "metadata": {
        "id": "-J7aOIL7HDpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function that will enable batch processing of multiple polygons in separate GeoTIFF files"
      ],
      "metadata": {
        "id": "6uTlPMn0caek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Iterate over the list of polygons and start an export task for each one.\n",
        "def batch_processing_polygons(polygons_to_export):\n",
        "    print(\"--- Starting Batch GeoTIFF Export Tasks ---\")\n",
        "    for polygon in polygons_to_export:\n",
        "        export_polygon_to_geotiff(\n",
        "            coords=polygon['coordinates'],\n",
        "            name=polygon['name'],\n",
        "            folder=folder_name,\n",
        "            scale=resolution_meters\n",
        "        )\n",
        "    print(\"\\nAll export tasks have been initiated.\")\n",
        "    print(\"Check the Colab 'Tasks' tab or run 'ee.batch.data.getTaskList().getInfo()' to monitor progress.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aPVESk2OHEC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "VE4cZynBcXry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the polygons in GeoJSON with Gemini AI's help to speed up the process"
      ],
      "metadata": {
        "id": "tBsW-76uckB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This part is generated by AI. In order to generate paste the Coordinates that appear under the map\n",
        "# when you create the polygons into a Gemini AI chat with following sentence:\n",
        "\n",
        "# \"Convert the following drawn polygon coordinates into a Python list named polygons_to_export,\n",
        "#assigning sequential names starting with Polygon_1_Export:\"\"\n",
        "\n",
        "# For the coordinates copy them in the same format that appears under the map. ie:\n",
        "\n",
        "# --- Drawn Polygon Coordinates ---\n",
        "# Exterior Ring Coordinates (GeoJSON format): [[146.919866, -34.722905], [146.93377, -34.724915], [146.933341, -34.728724], [146.919136, -34.727067], [146.919866, -34.722905]]\n",
        "# ----------------------------------------\n",
        "\n",
        "# --- Drawn Polygon Coordinates ---\n",
        "# Exterior Ring Coordinates (GeoJSON format): [[146.918192, -34.732534], [146.926904, -34.733592], [146.927848, -34.728231], [146.919136, -34.727137], [146.918192, -34.732534]]\n",
        "# ----------------------------------------\n",
        "\n",
        "#Then paste the output here.\n",
        "\n",
        "# polygons_to_export = [\n",
        "#     {\n",
        "#         'name': 'Polygon_A_Export',\n",
        "#         'coords': [\n",
        "#             [146.889825, -34.768324], [146.896262, -34.769452], [146.897206, -34.763423], [146.891069, -34.762224], [146.889782, -34.767936], [146.889825, -34.768324]\n",
        "#         ]\n",
        "#     },\n",
        "#     {\n",
        "#         'name': 'Polygon_B_Export',\n",
        "#         'coords': [\n",
        "#             [146.89652, -34.769416], [146.903043, -34.770298], [146.903987, -34.76508], [146.897507, -34.763599], [146.89652, -34.769416]\n",
        "#         ]\n",
        "#     },\n",
        "#     {\n",
        "#         'name': 'Polygon_C_Export',\n",
        "#         'coords': [\n",
        "#             [146.903644, -34.770333], [146.909995, -34.771461], [146.910768, -34.766385], [146.904416, -34.764939], [146.903644, -34.770333]\n",
        "#         ]\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "polygons_to_export = [\n",
        "    {\n",
        "        \"name\": \"Polygon_1_Export\",\n",
        "        \"coordinates\": [\n",
        "            [146.919866, -34.722905],\n",
        "            [146.93377, -34.724915],\n",
        "            [146.933341, -34.728724],\n",
        "            [146.919136, -34.727067],\n",
        "            [146.919866, -34.722905]\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Polygon_2_Export\",\n",
        "        \"coordinates\": [\n",
        "            [146.918192, -34.732534],\n",
        "            [146.926904, -34.733592],\n",
        "            [146.927848, -34.728231],\n",
        "            [146.919136, -34.727137],\n",
        "            [146.918192, -34.732534]\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Polygon_3_Export\",\n",
        "        \"coordinates\": [\n",
        "            [146.927161, -34.733627],\n",
        "            [146.935229, -34.734685],\n",
        "            [146.936259, -34.729042],\n",
        "            [146.928191, -34.728266],\n",
        "            [146.927161, -34.733627]\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "hvsR1i8_HaRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the batching process. This will create a GeoTIFF file per polygon and save in the folder for the specified bounding box central point."
      ],
      "metadata": {
        "id": "aoP5LeTcctYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This may take a few minutes."
      ],
      "metadata": {
        "id": "7qG0XaaVc22W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_processing_polygons(polygons_to_export)"
      ],
      "metadata": {
        "id": "xj1eWzO_Hreu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To check if the polygons look correct you can view a couple of the GeoTiff files"
      ],
      "metadata": {
        "id": "-ROFsmn9c48y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- View Exported GeoTIFF in Colab ---\n",
        "# This script requires the following libraries. If they are not installed, run:\n",
        "# !pip install rasterio matplotlib\n",
        "\n",
        "\n",
        "# Function to read and plot a single GeoTIFF\n",
        "def plot_geotiff(file_name, folder_name, drive_path):\n",
        "    \"\"\"Reads a GeoTIFF and plots the boundary data.\"\"\"\n",
        "\n",
        "    geotiff_path = os.path.join(\n",
        "        drive_path,\n",
        "        'MyDrive',\n",
        "        folder_name,\n",
        "        f'{file_name}.tif'\n",
        "    )\n",
        "\n",
        "    print(f\"Looking for file: {file_name}.tif\")\n",
        "\n",
        "    if not os.path.exists(geotiff_path):\n",
        "        print(f\"-> ERROR: File '{file_name}.tif' not found. Ensure the export task is COMPLETED.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with rasterio.open(geotiff_path) as src:\n",
        "            # Read the boundary band (which contains 1s for the border and 0s elsewhere)\n",
        "            boundary_data = src.read(1)\n",
        "\n",
        "            # Count how many non-zero pixels (borders) exist to ensure file isn't empty\n",
        "            if np.sum(boundary_data) == 0:\n",
        "                print(f\"-> WARNING: File '{file_name}.tif' contains no boundary data (all zeros).\")\n",
        "                return\n",
        "\n",
        "            # 5. Plot the data\n",
        "            plt.figure(figsize=(8, 8))\n",
        "\n",
        "            # Use 'interpolation=None' to show the sharp, 10m pixel boundaries\n",
        "            # Use a colormap suitable for binary data (like 'Greys')\n",
        "            plt.imshow(boundary_data, cmap='Greys', interpolation='none')\n",
        "\n",
        "            plt.title(f'GeoTIFF Visualization: {file_name}.tif')\n",
        "            plt.xlabel('Pixel Column')\n",
        "            plt.ylabel('Pixel Row')\n",
        "\n",
        "            # Since the image is just a border, we only need to show the value 1\n",
        "            plt.colorbar(label='Boundary Value (1 = Border)', ticks=[0, 1])\n",
        "\n",
        "            plt.show()\n",
        "            print(f\"Successfully displayed GeoTIFF for {file_name}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing GeoTIFF file {file_name}: {e}\")\n"
      ],
      "metadata": {
        "id": "9ci9bLtAHtvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Batch Visualization ---\n",
        "\n",
        "\n",
        "# The base path where Google Drive is mounted\n",
        "drive_mount_path = '/content/drive'\n",
        "\n",
        "\n",
        "# Define the list of file names you want to view.\n",
        "# UPDATE THIS LIST to match the 'name' field in your polygons_to_export list.\n",
        "file_names_to_view = [\n",
        "    'Polygon_1_Export',\n",
        "    'Polygon_2_Export',\n",
        "    'Polygon_3_Export'\n",
        "]\n",
        "\n",
        "for name in file_names_to_view:\n",
        "    plot_geotiff(name, folder_name, drive_mount_path)\n",
        "\n",
        "print(\"\\n--- Batch Visualization Attempt Complete ---\")\n"
      ],
      "metadata": {
        "id": "EH6-tMCrKNe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract other necessary layers for the defined Bounding Box that will be used for training."
      ],
      "metadata": {
        "id": "iUWZChkUdM6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up date ranges, bands and indicies required from Sentinel-2"
      ],
      "metadata": {
        "id": "AavazdNNkmbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def add_indices(image):\n",
        "    \"\"\"\n",
        "    Calculates NDVI and SAVI, and applies a smoothing filter to NDVI.\n",
        "    The resulting image will have the new bands: 'NDVI' (smoothed) and 'SAVI'.\n",
        "    \"\"\"\n",
        "    # 1. Calculate NDVI: (B8 - B4) / (B8 + B4)\n",
        "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI_raw')\n",
        "\n",
        "    # 2. Smooth NDVI using a 3x3 median filter to reduce noise while preserving edges\n",
        "    # The kernel is set to a radius of 1 pixel, resulting in a 3x3 window (2*1 + 1)\n",
        "    ndvi_smoothed = ndvi.focal_median(radius=1, kernelType='square', units='pixels').rename('NDVI')\n",
        "\n",
        "    # 3. Calculate SAVI: Soil Adjusted Vegetation Index (L=0.5)\n",
        "    # SAVI = ((B8 - B4) / (B8 + B4 + L)) * (1 + L)\n",
        "    L = ee.Number(0.5)\n",
        "    savi = image.expression(\n",
        "        '((NIR - RED) / (NIR + RED + L)) * (1 + L)', {\n",
        "            'NIR': image.select('B8'),\n",
        "            'RED': image.select('B4'),\n",
        "            'L': L\n",
        "        }).rename('SAVI')\n",
        "\n",
        "    # Return the original image with the two new derived bands\n",
        "    return image.addBands(ndvi_smoothed).addBands(savi)\n"
      ],
      "metadata": {
        "id": "PHgQw6wyIf5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch configuration\n",
        "\n"
      ],
      "metadata": {
        "id": "52xiNFshnjMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TARGET BANDS now includes the two new indices (Smoothed NDVI and SAVI)\n",
        "TARGET_BANDS = ['B4', 'B3', 'B2', 'B8', 'NDVI', 'SAVI']\n",
        "EXPORT_SCALE = 10  # 10 meters resolution\n",
        "\n",
        "# Define different date ranges for separate GeoTIFF exports\n",
        "# Adjusted for Southern Hemisphere (NSW Riverina Winter Crops)\n",
        "DATE_RANGES = [\n",
        "    # 1a. Canola Peak (Early Spring): Captures the bright yellow flowering stage\n",
        "    {'start': '2024-09-01', 'end': '2024-09-30', 'name_suffix': 'CanolaPeak'},\n",
        "\n",
        "    # 1b. Barley Senescence (Mid-Spring): Barley starts ripening, maximizing contrast with green wheat.\n",
        "    {'start': '2024-10-01', 'end': '2024-10-31', 'name_suffix': 'BarleySenescence'},\n",
        "\n",
        "    # 1c. Wheat Peak (Late Spring): Wheat is fully developed/filling, while barley is dry.\n",
        "    {'start': '2024-11-01', 'end': '2024-11-30', 'name_suffix': 'WheatPeak'},\n",
        "\n",
        "    # 2. Establishment/Early Growth (Winter): Sowing and Emergence stage\n",
        "    {'start': '2024-05-01', 'end': '2024-07-31', 'name_suffix': 'Emergence'},\n",
        "\n",
        "    # 3. Post-Harvest/Bare Earth (Summer): Fields are typically bare or harvested\n",
        "    {'start': '2023-12-01', 'end': '2024-02-29', 'name_suffix': 'BareEarth'}\n",
        "]"
      ],
      "metadata": {
        "id": "INKj3xkSniby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export function"
      ],
      "metadata": {
        "id": "epxW1jUCnuiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def export_sentinel2_composite(date_range_config, geometry, folder_name):\n",
        "    \"\"\"\n",
        "    Filters Sentinel-2 data, creates a median composite with indices, and starts export.\n",
        "    \"\"\"\n",
        "    start_date = date_range_config['start']\n",
        "    end_date = date_range_config['end']\n",
        "    name_suffix = date_range_config['name_suffix']\n",
        "\n",
        "    # 1. Filter and process the ImageCollection\n",
        "    s2_collection = (\n",
        "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filterBounds(geometry)\n",
        "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "        .map(mask_s2_clouds)\n",
        "        # Add indices (NDVI, SAVI) and smooth NDVI\n",
        "        .map(add_indices)\n",
        "    )\n",
        "\n",
        "    # 2. Create the median composite and clip to the geometry\n",
        "    median_composite = s2_collection.median().clip(geometry)\n",
        "\n",
        "    # 3. Select only the required bands (now 6 total)\n",
        "    final_image = median_composite.select(TARGET_BANDS)\n",
        "\n",
        "    # 4. FIX: Cast the entire image to Float32 to ensure compatible data types across all bands\n",
        "    final_image = final_image.toFloat()\n",
        "\n",
        "    # 5. Define file name and description\n",
        "    file_name = f\"Sentinel2_{name_suffix}_{start_date.replace('-', '')}_{end_date.replace('-', '')}\"\n",
        "\n",
        "    print(f\"\\nStarting export for: {name_suffix} ({start_date} to {end_date})\")\n",
        "\n",
        "    # 6. Start the Export Task\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=final_image,\n",
        "        description=file_name,\n",
        "        folder=folder_name,       # Dynamic folder name\n",
        "        fileNamePrefix=file_name,\n",
        "        region=geometry.bounds(),\n",
        "        scale=EXPORT_SCALE,\n",
        "        fileFormat='GeoTIFF',\n",
        "        formatOptions={'cloudOptimized': True}\n",
        "    )\n",
        "\n",
        "    task.start()\n",
        "    print(f\"Task '{file_name}' started. Check Colab Tasks tab for progress.\")\n"
      ],
      "metadata": {
        "id": "icp_W6gFkpoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Execution"
      ],
      "metadata": {
        "id": "AMjxsLS6n98v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Execute the export for each defined date range\n",
        "    print(\"--- Starting Batch Sentinel-2 Export ---\")\n",
        "    for dr in DATE_RANGES:\n",
        "        export_sentinel2_composite(dr, bounding_box_geom, folder_name)\n",
        "\n",
        "    print(\"\\nAll export tasks submitted to Earth Engine.\")\n",
        "    print(\"Monitor the Colab Tasks tab for completion before starting U-Net training. Check progress here: https://console.cloud.google.com/earth-engine/tasks?project=cs88-2-capstone\")"
      ],
      "metadata": {
        "id": "4Llf2evwn52p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install scipy first"
      ],
      "metadata": {
        "id": "bsr0wIA-v8mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# U-NET MODEL FOR CROP BOUNDARY SEGMENTATION (MULTI-HEAD ARCHITECTURE)\n",
        "# Now adapted to load INDIVIDUAL FILLED POLYGON MASKS (exported from EE)\n",
        "# and generate the 2-channel Instance Label Map (Boundary + Distance) directly.\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "import scipy.ndimage as ndi # Required for Distance Transform (Instance Segmentation)\n",
        "from skimage.transform import resize # Required to align masks to a consistent shape\n",
        "\n",
        "# --- Configuration ---\n",
        "# Must match the 5 exports * 6 bands/export = 30 channels\n",
        "NUM_CHANNELS = 30\n",
        "TILE_SIZE = 256\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 25\n",
        "VALIDATION_SPLIT = 0.1\n",
        "OUTPUT_CHANNELS = 2 # Boundary Mask (0) and Distance Map (1)\n",
        "\n",
        "# --- Data Path Configuration ---\n",
        "# Ensure these match your export parameters\n",
        "center_lon = 146.9561\n",
        "center_lat = -34.7022\n",
        "folder_name = f\"BBox_{center_lon:.4f}_{center_lat:.4f}\".replace('.', '_').replace('-', '_')\n",
        "DRIVE_PATH = f'/content/drive/MyDrive/{folder_name}'\n",
        "\n",
        "# List of all five Sentinel-2 input files to be loaded and stacked\n",
        "INPUT_IMAGE_NAMES = [\n",
        "    'Sentinel2_CanolaPeak_20240901_20240930',\n",
        "    'Sentinel2_BarleySenescence_20241001_20241031',\n",
        "    'Sentinel2_WheatPeak_20241101_20241130',\n",
        "    'Sentinel2_Emergence_20240501_20240731',\n",
        "    'Sentinel2_BareEarth_20231201_20240229'\n",
        "]\n",
        "\n",
        "# The GeoTIFF mask files (labels) exported from the GeoJSON (must be FILLED polygons now)\n",
        "MASK_FILE_NAMES = [\n",
        "    'Polygon_1_Export',\n",
        "    'Polygon_2_Export',\n",
        "    'Polygon_3_Export'\n",
        "    # Add all other polygon mask exports here\n",
        "]"
      ],
      "metadata": {
        "id": "5hp-7TGawWou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# 2. DATA UTILITY FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def load_all_input_tiffs(image_names, path):\n",
        "    \"\"\"Loads all five Sentinel-2 time-series GeoTIFFs and stacks them.\"\"\"\n",
        "    stacked_images = []\n",
        "\n",
        "    # Load all 5 time-step images and stack them along the channel axis\n",
        "    for name in image_names:\n",
        "        file_path = os.path.join(path, f'{name}.tif')\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Error: Input file not found: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        with rasterio.open(file_path) as src:\n",
        "            # Read all 6 bands for this time step: (6, H, W)\n",
        "            img = src.read()\n",
        "            # Transpose to (H, W, 6) and append to stack\n",
        "            stacked_images.append(img.transpose((1, 2, 0)))\n",
        "\n",
        "    # Concatenate all 5 time steps: (H, W, 5 * 6) = (H, W, 30)\n",
        "    full_img_stack = np.concatenate(stacked_images, axis=2)\n",
        "    print(f\"Successfully loaded and stacked input image with shape: {full_img_stack.shape}\")\n",
        "\n",
        "    return full_img_stack\n",
        "\n",
        "\n",
        "def generate_instance_labels(mask_names, path, target_shape):\n",
        "    \"\"\"\n",
        "    Loads individual FILLED polygon masks, aligns them, generates their distance maps,\n",
        "    and combines everything into the final 2-channel label array (Boundary + Distance).\n",
        "    \"\"\"\n",
        "    target_h, target_w = target_shape[0], target_shape[1]\n",
        "\n",
        "    # Initialize the final label arrays\n",
        "    final_boundary_mask = np.zeros(target_shape, dtype=np.float32)\n",
        "    final_distance_map = np.zeros(target_shape, dtype=np.float32)\n",
        "\n",
        "    for name in mask_names:\n",
        "        file_path = os.path.join(path, f'{name}.tif')\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Warning: Mask file not found: {file_path}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with rasterio.open(file_path) as src:\n",
        "            # Read the single-band mask (Filled Polygon): (1, H, W)\n",
        "            mask_filled = src.read(1)\n",
        "\n",
        "            # 1. ALIGN MASK TO TARGET SHAPE (H, W)\n",
        "            if mask_filled.shape != target_shape:\n",
        "                mask_filled = resize(\n",
        "                    mask_filled,\n",
        "                    target_shape,\n",
        "                    order=0, # Nearest-neighbor interpolation\n",
        "                    preserve_range=True,\n",
        "                    anti_aliasing=False\n",
        "                ).astype(np.uint8)\n",
        "\n",
        "            # Normalize the mask to be 1.0 (inside) or 0.0 (outside)\n",
        "            mask_filled = (mask_filled > 0).astype(np.float32)\n",
        "\n",
        "            # 2. GENERATE BOUNDARY MASK (Channel 0)\n",
        "            # Find the boundary by subtracting the eroded mask from the original filled mask.\n",
        "            # Erode the mask by one pixel (or use a different method if preferred)\n",
        "            eroded_mask = ndi.binary_erosion(mask_filled, iterations=1)\n",
        "            field_boundary = mask_filled - eroded_mask\n",
        "\n",
        "            # Combine this field's boundary with the final boundary mask (logical OR)\n",
        "            final_boundary_mask = np.maximum(final_boundary_mask, field_boundary)\n",
        "\n",
        "            # 3. GENERATE DISTANCE MAP (Channel 1)\n",
        "            # Compute Euclidean Distance Transform from the interior (value 1) to the boundary (value 0).\n",
        "            distance_to_boundary = ndi.distance_transform_edt(mask_filled)\n",
        "\n",
        "            # Combine distance maps: We want the *maximum* distance for the center of the fields.\n",
        "            final_distance_map = np.maximum(final_distance_map, distance_to_boundary)\n",
        "\n",
        "\n",
        "    # 4. Final Normalization and Stacking\n",
        "\n",
        "    # Normalize the combined distance map to 0-1 range\n",
        "    distance_max = final_distance_map.max()\n",
        "    if distance_max > 0:\n",
        "        final_distance_map /= distance_max\n",
        "\n",
        "    # Stack the two channels: (H, W, 2)\n",
        "    label_2ch = np.dstack([\n",
        "        np.expand_dims(final_boundary_mask, axis=-1),\n",
        "        np.expand_dims(final_distance_map, axis=-1)\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "    print(f\"Successfully generated 2-channel label map with shape: {label_2ch.shape}\")\n",
        "    return label_2ch\n",
        "\n",
        "\n",
        "def create_tiles(full_img, full_mask_2ch, tile_size):\n",
        "    \"\"\"Slides a window across the full image/mask to create fixed-size training tiles.\"\"\"\n",
        "    height, width, _ = full_img.shape\n",
        "    X_tiles = []\n",
        "    Y_tiles = []\n",
        "\n",
        "    # Iterate with a non-overlapping sliding window\n",
        "    for y in range(0, height - tile_size + 1, tile_size):\n",
        "        for x in range(0, width - tile_size + 1, tile_size):\n",
        "            # Extract image tile (X)\n",
        "            img_tile = full_img[y:y + tile_size, x:x + tile_size, :]\n",
        "\n",
        "            # Extract the 2-channel mask tile (Y)\n",
        "            mask_tile = full_mask_2ch[y:y + tile_size, x:x + tile_size, :]\n",
        "\n",
        "            # Only include tiles that contain at least one boundary pixel (for efficiency)\n",
        "            if np.any(mask_tile[:, :, 0]):\n",
        "                X_tiles.append(img_tile)\n",
        "                Y_tiles.append(mask_tile)\n",
        "\n",
        "    X_train = np.array(X_tiles)\n",
        "    Y_train = np.array(Y_tiles)\n",
        "\n",
        "    print(f\"Tiling complete. Generated {len(X_tiles)} training tiles.\")\n",
        "    return X_train, Y_train\n"
      ],
      "metadata": {
        "id": "E9RkK5a38fYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom Loss Function to handle the two different output types\n",
        "def multi_head_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Loss function for the 2-channel output:\n",
        "    Channel 0 (Boundary Mask): Binary Crossentropy\n",
        "    Channel 1 (Distance Map): Mean Squared Error\n",
        "    \"\"\"\n",
        "    # Channel 0: Boundary Mask (Binary Segmentation)\n",
        "    y_true_boundary = y_true[:, :, :, 0]\n",
        "    y_pred_boundary = y_pred[:, :, :, 0]\n",
        "\n",
        "    # Calculate Binary Crossentropy. Output shape: (batch, H, W)\n",
        "    boundary_loss_per_pixel = K.binary_crossentropy(y_true_boundary, y_pred_boundary)\n",
        "    # CRITICAL FIX: Take the mean over the spatial dimensions (H and W) to get shape (batch,)\n",
        "    boundary_loss = K.mean(boundary_loss_per_pixel, axis=[1, 2])\n",
        "\n",
        "    # Channel 1: Distance Map (Regression)\n",
        "    y_true_distance = y_true[:, :, :, 1]\n",
        "    y_pred_distance = y_pred[:, :, :, 1]\n",
        "\n",
        "    # Mean Squared Error for the distance prediction. Output shape: (batch, H, W)\n",
        "    distance_loss_per_pixel = K.square(y_pred_distance - y_true_distance)\n",
        "    # CRITICAL FIX: Take the mean over the spatial dimensions (H and W) to get shape (batch,)\n",
        "    distance_loss = K.mean(distance_loss_per_pixel, axis=[1, 2])\n",
        "\n",
        "    # Combine the losses (now both are the compatible shape (batch,))\n",
        "    total_loss = boundary_loss + (0.5 * distance_loss)\n",
        "    return total_loss\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    \"\"\"Defines a Multi-Head U-Net architecture for instance segmentation hint prediction.\"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder (Downsampling Path) - Stays the same\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "\n",
        "    # Decoder (Upsampling Path) - Stays the same\n",
        "    up5 = concatenate([UpSampling2D(size=(2, 2))(drop4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output layer (CRITICAL CHANGE: 2 channels for Boundary + Distance Map)\n",
        "    outputs = Conv2D(OUTPUT_CHANNELS, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                  loss=multi_head_loss,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "2O7_Hm2k8fVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# 4. EXECUTION\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # 1. Mount Google Drive and check for dependencies (you must run these in Colab)\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # !pip install rasterio scipy scikit-image # All needed for the new pipeline\n",
        "\n",
        "    # 2. Data Loading and Preprocessing\n",
        "    print(\"\\n--- Starting Data Loading and Preprocessing (Step 1) ---\")\n",
        "\n",
        "    # Load and stack all 5 Sentinel-2 GeoTIFFs into one massive (H, W, 30) input array\n",
        "    full_img_stack = load_all_input_tiffs(INPUT_IMAGE_NAMES, DRIVE_PATH)\n",
        "\n",
        "    if full_img_stack is None:\n",
        "        print(\"Aborting training due to missing Sentinel-2 input files.\")\n",
        "        exit()\n",
        "\n",
        "    # Get the target shape (H, W) from the loaded input stack\n",
        "    target_shape_hw = full_img_stack.shape[:2]\n",
        "    print(f\"Target mask shape set to: {target_shape_hw}\")\n",
        "\n",
        "    # --- CRITICAL NEW STEP FOR INSTANCE SEGMENTATION LABEL GENERATION ---\n",
        "    print(\"\\n--- Generating 2-Channel Instance Label Map from FILLED MASKS ---\")\n",
        "\n",
        "    # This function handles the resizing, boundary finding, distance map calculation, and stacking.\n",
        "    full_mask_2ch = generate_instance_labels(MASK_FILE_NAMES, DRIVE_PATH, target_shape_hw)\n",
        "\n",
        "    if full_mask_2ch is None:\n",
        "        print(\"Aborting training due to missing or uncombinable mask files.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"2-channel (Boundary + Distance) label map created with shape: {full_mask_2ch.shape}\")\n",
        "    # ----------------------------------------------------\n",
        "\n",
        "\n",
        "    # 3. Tiling and Splitting\n",
        "    print(\"\\n--- Tiling Data (Step 2) ---\")\n",
        "    X_tiles, Y_tiles = create_tiles(full_img_stack, full_mask_2ch, TILE_SIZE)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "        X_tiles, Y_tiles, test_size=VALIDATION_SPLIT, random_state=42\n",
        "    )\n",
        "    print(f\"Training set size: {X_train.shape[0]} tiles\")\n",
        "    print(f\"Validation set size: {X_val.shape[0]} tiles\")\n",
        "\n",
        "\n",
        "    # 4. Model Setup and Training\n",
        "    print(\"\\n--- Training U-Net Model (Step 3) ---\")\n",
        "    input_shape = (TILE_SIZE, TILE_SIZE, NUM_CHANNELS)\n",
        "    unet_model = build_unet(input_shape)\n",
        "\n",
        "    history = unet_model.fit(\n",
        "        X_train,\n",
        "        Y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, Y_val),\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nâœ… Training complete.\")\n",
        "\n",
        "    # 5. Save the trained model\n",
        "    model_save_path = os.path.join(DRIVE_PATH, 'crop_boundary_instance_unet_model.keras')\n",
        "    unet_model.save(model_save_path)\n",
        "    print(f\"Model saved to: {model_save_path}\")"
      ],
      "metadata": {
        "id": "ADGUeRzN8fSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gf5wjE7H8fN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zznis6OZ8fGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# 3. U-NET ARCHITECTURE (MULTI-HEAD)\n",
        "# ==============================================================================\n",
        "\n",
        "# Custom Loss Function to handle the two different output types\n",
        "def multi_head_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Loss function for the 2-channel output:\n",
        "    Channel 0 (Boundary Mask): Binary Crossentropy\n",
        "    Channel 1 (Distance Map): Mean Squared Error\n",
        "    \"\"\"\n",
        "    # Channel 0: Boundary Mask (Binary Segmentation)\n",
        "    y_true_boundary = y_true[:, :, :, 0]\n",
        "    y_pred_boundary = y_pred[:, :, :, 0]\n",
        "\n",
        "    # We use a weight map to focus the loss on the boundary pixels (y_true_boundary)\n",
        "    # Binary Crossentropy for the boundary prediction\n",
        "    boundary_loss = K.binary_crossentropy(y_true_boundary, y_pred_boundary)\n",
        "\n",
        "    # Channel 1: Distance Map (Regression)\n",
        "    y_true_distance = y_true[:, :, :, 1]\n",
        "    y_pred_distance = y_pred[:, :, :, 1]\n",
        "\n",
        "    # Mean Squared Error for the distance prediction\n",
        "    distance_loss = K.mean(K.square(y_pred_distance - y_true_distance), axis=-1)\n",
        "\n",
        "    # Combine the losses (weights can be adjusted if one task dominates)\n",
        "    total_loss = boundary_loss + (0.5 * distance_loss)\n",
        "    return total_loss\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    \"\"\"Defines a Multi-Head U-Net architecture for instance segmentation hint prediction.\"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder (Downsampling Path) - Stays the same\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "\n",
        "    # Decoder (Upsampling Path) - Stays the same\n",
        "    up5 = concatenate([UpSampling2D(size=(2, 2))(drop4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output layer (CRITICAL CHANGE: 2 channels for Boundary + Distance Map)\n",
        "    outputs = Conv2D(OUTPUT_CHANNELS, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                  loss=multi_head_loss,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eEIK0fMA4ePW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.ndimage as ndi # You must add this import!\n",
        "\n",
        "def generate_distance_map(binary_mask_1ch):\n",
        "    \"\"\"\n",
        "    Generates a 2-channel label mask (Boundary + Distance).\n",
        "    Channel 0: Original binary mask (Boundary).\n",
        "    Channel 1: Euclidean Distance Transform (for instance separation).\n",
        "    \"\"\"\n",
        "    # 1. Compute the Euclidean Distance Transform on the NEGATIVE of the mask.\n",
        "    # This measures the distance from every background pixel to the nearest field boundary.\n",
        "    # The `binary_mask_1ch` must be inverted (0 for foreground, 1 for background)\n",
        "    # for the distance to measure the distance to the field interior.\n",
        "\n",
        "    # We actually want the distance from the boundary *into* the field area.\n",
        "    # Assuming your original GeoTIFF masks were 1 inside the polygon and 0 outside.\n",
        "    # We want distance from 0 (boundary/background) to the interior (1).\n",
        "\n",
        "    # We need a mask where the boundary is 0 and the interior is 1.\n",
        "\n",
        "    # A simple boundary mask (Y_train[:,:,0]) is 1 only on the boundary.\n",
        "    # To get the distance to the interior, we compute the distance transform on the interior pixels.\n",
        "    # For instance segmentation, it's common to compute the distance from the background\n",
        "    # to the instance boundary, then invert and normalize it.\n",
        "\n",
        "    # Simplified approach for demonstration (requires the actual field interiors):\n",
        "    # This requires running a second Earth Engine export to get the *filled* polygon area,\n",
        "    # not just the boundary line you currently have.\n",
        "    # Given we only have the *boundary* right now, let's stick to the simplest\n",
        "    # instance separation hint: the distance from the predicted boundary.\n",
        "\n",
        "    # For now, let's assume the interior mask (1=inside, 0=outside) is available.\n",
        "    # Since you only provided boundary masks, this part is tricky.\n",
        "\n",
        "    # ----------------------------------------------------\n",
        "    # TEMPORARY INSTANCE HINT (DISTANCE FROM BOUNDARY)\n",
        "    # ----------------------------------------------------\n",
        "\n",
        "    # 1. Use the binary boundary mask (1 where there is a line, 0 otherwise)\n",
        "    boundary_binary = binary_mask_1ch[:,:,0]\n",
        "\n",
        "    # 2. Compute distance from the boundary (where boundary_binary == 1)\n",
        "    # The distance transform measures the distance from 0-valued pixels.\n",
        "    # We invert the boundary mask: 0 (boundary) -> 1 (background), 1 (boundary) -> 0\n",
        "    # The current mask has 1 for boundary, 0 for background.\n",
        "    # We want distance from the nearest boundary pixel (which is 1).\n",
        "    # Use the distance transform on the inverted mask to get distance *to* the boundary:\n",
        "    distance_to_boundary = ndi.distance_transform_edt(1 - boundary_binary)\n",
        "\n",
        "    # 3. Normalize the distance map for better network learning (0 to 1)\n",
        "    distance_max = distance_to_boundary.max()\n",
        "    distance_map = distance_to_boundary / distance_max if distance_max > 0 else distance_to_boundary\n",
        "\n",
        "    # 4. Stack them back up: Channel 0 is boundary, Channel 1 is normalized distance\n",
        "    label_2ch = np.dstack([boundary_binary, distance_map])\n",
        "\n",
        "    return label_2ch\n",
        "\n",
        "\n",
        "# --- In __main__ (REPLACING THE PLACEHOLDER) ---\n",
        "# You need to run: !pip install scipy first\n",
        "\n",
        "# Load the binary boundary mask\n",
        "full_boundary_mask_1ch = load_and_combine_masks(MASK_FILE_NAMES, DRIVE_PATH)\n",
        "# Generate the 2-channel label (Boundary + Distance)\n",
        "full_mask_2ch = generate_distance_map(full_boundary_mask_1ch)\n"
      ],
      "metadata": {
        "id": "0a9t2MAcoCsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# 4. EXECUTION\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # 1. Mount Google Drive and check for dependencies (you must run these in Colab)\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # !pip install rasterio scipy # You MUST install scipy now!\n",
        "\n",
        "    # 2. Data Loading and Preprocessing\n",
        "    print(\"\\n--- Starting Data Loading and Preprocessing (Step 1) ---\")\n",
        "\n",
        "    # Load and stack all 5 Sentinel-2 GeoTIFFs into one massive (H, W, 30) input array\n",
        "    full_img_stack = load_all_input_tiffs(INPUT_IMAGE_NAMES, DRIVE_PATH)\n",
        "\n",
        "    # Load and combine all polygon GeoTIFFs into one massive (H, W, 1) mask array (Boundary only)\n",
        "    full_boundary_mask_1ch = load_and_combine_masks(MASK_FILE_NAMES, DRIVE_PATH)\n",
        "\n",
        "    if full_img_stack is None or full_boundary_mask_1ch is None:\n",
        "        print(\"Aborting training due to missing input files.\")\n",
        "        exit()\n",
        "\n",
        "    # --- CRITICAL NEW STEP FOR INSTANCE SEGMENTATION ---\n",
        "    print(\"\\n--- Generating 2-Channel Instance Label Map (Boundary + Distance) ---\")\n",
        "\n",
        "    # We need a function that takes full_boundary_mask_1ch and adds the distance map.\n",
        "    # THIS CODE IS A PLACEHOLDER. You need to implement the distance transform here.\n",
        "    # Since the necessary library `scipy.ndimage` is not imported, we skip the actual\n",
        "    # creation here and explain the next step.\n",
        "\n",
        "    # âš ï¸ Placeholder: This needs to be replaced with the actual 2-channel mask generation\n",
        "    # where Y_train[:, :, 0] = boundary, and Y_train[:, :, 1] = distance map.\n",
        "    full_mask_2ch = np.dstack([full_boundary_mask_1ch, full_boundary_mask_1ch * 0.5])\n",
        "    print(f\"Placeholder 2-channel mask created with shape: {full_mask_2ch.shape}\")\n",
        "    # ----------------------------------------------------\n",
        "\n",
        "\n",
        "    # 3. Tiling and Splitting\n",
        "    print(\"\\n--- Tiling Data (Step 2) ---\")\n",
        "    X_tiles, Y_tiles = create_tiles(full_img_stack, full_mask_2ch, TILE_SIZE)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "        X_tiles, Y_tiles, test_size=VALIDATION_SPLIT, random_state=42\n",
        "    )\n",
        "    print(f\"Training set size: {X_train.shape[0]} tiles\")\n",
        "    print(f\"Validation set size: {X_val.shape[0]} tiles\")\n",
        "\n",
        "\n",
        "    # 4. Model Setup and Training\n",
        "    print(\"\\n--- Training U-Net Model (Step 3) ---\")\n",
        "    input_shape = (TILE_SIZE, TILE_SIZE, NUM_CHANNELS)\n",
        "    unet_model = build_unet(input_shape)\n",
        "\n",
        "    history = unet_model.fit(\n",
        "        X_train,\n",
        "        Y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=1,\n",
        "        validation_data=(X_val, Y_val),\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nâœ… Training complete.\")\n",
        "\n",
        "    # 5. Save the trained model\n",
        "    model_save_path = os.path.join(DRIVE_PATH, 'crop_boundary_instance_unet_model.keras')\n",
        "    unet_model.save(model_save_path)\n",
        "    print(f\"Model saved to: {model_save_path}\")"
      ],
      "metadata": {
        "id": "7WPHkGF6wEZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}